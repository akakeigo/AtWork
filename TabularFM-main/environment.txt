# ---- CUDA 12.4 PyTorch wheels ----
# --extra-index-url https://download.pytorch.org/whl/cu124
torch==2.4.1

# ---- HF stack & training utils ----
transformers==4.43.3
tokenizers==0.19.1
accelerate==0.33.0
datasets>=2.20.0
huggingface-hub>=0.24.0
safetensors>=0.4.4
einops>=0.7.0
sentencepiece>=0.1.99

# ---- Numeric / data / viz ----
numpy>=1.26.4
pandas>=2.2.2
pyarrow>=15.0.0
fsspec>=2024.2.0
matplotlib>=3.8.4
tqdm>=4.66.4
termcolor>=2.4.0

# ---- Logging ----
wandb>=0.17.0

# ---- Datasets used in your code ----
relbench

# ---- Optional: enable FlashAttention-2 path in Transformers/Qwen2 ----
# If the prebuilt wheel for your CUDA version is unavailable on your platform,
# you can comment this out and Transformers will fall back gracefully.
